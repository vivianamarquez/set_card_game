{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7ebf8d-8023-4e08-86ae-8a13e6db9863",
   "metadata": {},
   "source": [
    "# Get all sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc4b926-d3ea-41a6-87d2-85ab5131c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106605a4-e1de-41d1-8fcb-f435375fe466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# card namedtuple type\n",
    "Card = namedtuple('card', ['number', 'color', 'shape', 'shade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a63bbf2-62d6-4fde-a7e2-e84e6eb528ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# characteristics\n",
    "numbers = ['one', 'two', 'three']\n",
    "colors = ['green', 'purple', 'red']\n",
    "shapes = ['diamond', 'squiggle', 'oval']\n",
    "shades = ['open', 'solid', 'striped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad1d294-67aa-472a-aab4-15aef147dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all cards \n",
    "all_cards = {\n",
    "    Card(number=number, color=color, shape=shape, shade=shade)\n",
    "    for number in numbers\n",
    "    for color in colors\n",
    "    for shape in shapes\n",
    "    for shade in shades\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "044596bc-ff27-4542-8b14-cf8ff358013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 81 cards in total.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(all_cards)} cards in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c5666ad-f85a-47ec-8de9-c573c0e3f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cards_list = list(all_cards)\n",
    "possible_sets = list(itertools.combinations(all_cards_list, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e42acffb-f430-4580-ae3d-50e9ae8b58f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 85,320 different 3 card combinations in total.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(possible_sets):,} different 3 card combinations in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b45f7531-2f82-4641-ab72-5be05779eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_valid(candidate_set):\n",
    "    set_numbers = set()\n",
    "    set_colors = set()\n",
    "    set_shapes = set()\n",
    "    set_shades = set()\n",
    "    \n",
    "    for card in candidate_set:\n",
    "        set_numbers.add(card.number)\n",
    "        set_colors.add(card.color)\n",
    "        set_shapes.add(card.shape)\n",
    "        set_shades.add(card.shade)\n",
    "\n",
    "    set_totals = {len(set_numbers), len(set_colors), len(set_shapes), len(set_shades)}\n",
    "    \n",
    "    if set_totals in [{1},{3},{1,3}]:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d04ce6b-1096-44f7-8289-def359c2ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sets, invalid_sets = set(), set()\n",
    "\n",
    "for candidate_set in possible_sets:\n",
    "    (valid_sets if check_if_valid(candidate_set) else invalid_sets).add(candidate_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc3f7fd1-32e9-4d71-b46a-5c348c645782",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(valid_sets)+len(invalid_sets) == len(possible_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "361e63ae-b94a-4873-864d-cd7f0f85e06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,080 valid sets and 84,240 invalid sets.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(valid_sets):,} valid sets and {len(invalid_sets):,} invalid sets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c69a72c-6a6b-44c3-be87-11a1ba8531d9",
   "metadata": {},
   "source": [
    "# Get training dataset for DL task \n",
    "Dataset obtained from Kaggle: https://www.kaggle.com/datasets/kwisatzhaderach/set-cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2d173fa-516d-44e1-bb25-28b006917a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00eb601a-8b3e-40dc-bc14-3a6fc1459f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_folder_tree(base_dir, indent=''):\n",
    "    items = os.listdir(base_dir)\n",
    "    \n",
    "    items = [item for item in items if os.path.isdir(os.path.join(base_dir, item))]\n",
    "    \n",
    "    for index, item in enumerate(items):\n",
    "        item_path = os.path.join(base_dir, item)\n",
    "        is_last = index == len(items) - 1\n",
    "        \n",
    "        if is_last:\n",
    "            print(indent + '└── ' + item)\n",
    "            new_indent = indent + '    '\n",
    "        else:\n",
    "            print(indent + '├── ' + item)\n",
    "            new_indent = indent + '│   '\n",
    "        \n",
    "        print_folder_tree(item_path, new_indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c60bfae7-b52f-427e-bbc3-7fe59fcd07ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── one\n",
      "│   ├── green\n",
      "│   │   ├── diamond\n",
      "│   │   │   ├── solid\n",
      "│   │   │   ├── striped\n",
      "│   │   │   └── open\n",
      "│   │   ├── squiggle\n",
      "│   │   │   ├── solid\n",
      "│   │   │   ├── striped\n",
      "│   │   │   └── open\n",
      "│   │   └── oval\n",
      "│   │       ├── solid\n",
      "│   │       ├── striped\n",
      "│   │       └── open\n",
      "│   ├── red\n",
      "│   │   ├── diamond\n",
      "│   │   │   ├── solid\n",
      "│   │   │   ├── striped\n",
      "│   │   │   └── open\n",
      "│   │   ├── squiggle\n",
      "│   │   │   ├── solid\n",
      "│   │   │   ├── striped\n",
      "│   │   │   └── open\n",
      "│   │   └── oval\n",
      "│   │       ├── solid\n",
      "│   │       ├── striped\n",
      "│   │       └── open\n",
      "│   └── purple\n",
      "│       ├── diamond\n",
      "│       │   ├── solid\n",
      "│       │   ├── striped\n",
      "│       │   └── open\n",
      "│       ├── squiggle\n",
      "│       │   ├── solid\n",
      "│       │   ├── striped\n",
      "│       │   └── open\n",
      "│       └── oval\n",
      "│           ├── solid\n",
      "│           ├── striped\n",
      "│           └── open\n",
      "├── zthree\n",
      "│   ├── green\n",
      "│   │   ├── diamond\n",
      "│   │   │   ├── solid\n",
      "│   │   │   ├── striped\n",
      "│   │   │   └── open\n",
      "│   │   ├── squiggle\n",
      "│   │   │   ├── solid\n",
      "│   │   │   ├── striped\n",
      "│   │   │   └── open\n",
      "│   │   └── oval\n",
      "│   │       ├── solid\n",
      "│   │       ├── striped\n",
      "│   │       └── open\n",
      "│   ├── red\n",
      "│   │   ├── diamond\n",
      "│   │   │   ├── solid\n",
      "│   │   │   ├── striped\n",
      "│   │   │   └── open\n",
      "│   │   ├── squiggle\n",
      "│   │   │   ├── solid\n",
      "│   │   │   ├── striped\n",
      "│   │   │   └── open\n",
      "│   │   └── oval\n",
      "│   │       ├── solid\n",
      "│   │       ├── striped\n",
      "│   │       └── open\n",
      "│   └── purple\n",
      "│       ├── diamond\n",
      "│       │   ├── solid\n",
      "│       │   ├── striped\n",
      "│       │   └── open\n",
      "│       ├── squiggle\n",
      "│       │   ├── solid\n",
      "│       │   ├── striped\n",
      "│       │   └── open\n",
      "│       └── oval\n",
      "│           ├── solid\n",
      "│           ├── striped\n",
      "│           └── open\n",
      "└── two\n",
      "    ├── green\n",
      "    │   ├── diamond\n",
      "    │   │   ├── solid\n",
      "    │   │   ├── striped\n",
      "    │   │   └── open\n",
      "    │   ├── squiggle\n",
      "    │   │   ├── solid\n",
      "    │   │   ├── striped\n",
      "    │   │   └── open\n",
      "    │   └── oval\n",
      "    │       ├── solid\n",
      "    │       ├── striped\n",
      "    │       └── open\n",
      "    ├── red\n",
      "    │   ├── diamond\n",
      "    │   │   ├── solid\n",
      "    │   │   ├── striped\n",
      "    │   │   └── open\n",
      "    │   ├── squiggle\n",
      "    │   │   ├── solid\n",
      "    │   │   ├── striped\n",
      "    │   │   └── open\n",
      "    │   └── oval\n",
      "    │       ├── solid\n",
      "    │       ├── striped\n",
      "    │       └── open\n",
      "    └── purple\n",
      "        ├── diamond\n",
      "        │   ├── solid\n",
      "        │   ├── striped\n",
      "        │   └── open\n",
      "        ├── squiggle\n",
      "        │   ├── solid\n",
      "        │   ├── striped\n",
      "        │   └── open\n",
      "        └── oval\n",
      "            ├── solid\n",
      "            ├── striped\n",
      "            └── open\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'dataset'\n",
    "print_folder_tree(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118445c-d3f6-4df5-9056-30d76fefc530",
   "metadata": {},
   "source": [
    "# Create a Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02f4fd16-b71d-416b-b6b3-a4e1d27fb12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc8fbdb3-a246-4729-8849-6fd05fd514c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardDetectionDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        with open(annotation_file) as f:\n",
    "            self.annotations = json.load(f)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        annotation = self.annotations[idx]\n",
    "        img_path = os.path.join(self.root_dir, annotation[\"image\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        boxes = torch.tensor(annotation[\"boxes\"], dtype=torch.float32)\n",
    "        labels = torch.tensor(annotation[\"labels\"], dtype=torch.int64)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3d1102a-498e-4d33-b0b5-d2e1616a9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((50, 50)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = CardDataset(root_dir='dataset', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a7f4d8-87d4-4131-a99b-3967a3739da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa9b1d7e-10b0-43e6-bc68-097dd2ceb332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivianamarquez/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/vivianamarquez/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(dataset.classes))  # Change the output layer to match the number of classes\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b7a1d96-2c5a-47b4-b8b6-c28a42b77a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79c034e2-157c-4da8-971b-04a4266e9a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.1809, Validation Accuracy: 1.0000\n",
      "Epoch 2/25, Loss: 0.0085, Validation Accuracy: 1.0000\n",
      "Epoch 3/25, Loss: 0.0067, Validation Accuracy: 1.0000\n",
      "Epoch 4/25, Loss: 0.0056, Validation Accuracy: 1.0000\n",
      "Epoch 5/25, Loss: 0.0109, Validation Accuracy: 1.0000\n",
      "Epoch 6/25, Loss: 0.0083, Validation Accuracy: 0.9974\n",
      "Epoch 7/25, Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch 8/25, Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch 9/25, Loss: 0.0197, Validation Accuracy: 1.0000\n",
      "Epoch 10/25, Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch 11/25, Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch 12/25, Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch 13/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 14/25, Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch 15/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 16/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 17/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 18/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 19/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 20/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 21/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 22/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 23/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 24/25, Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch 25/25, Loss: 0.0000, Validation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1a29ae0-e629-481f-b51a-c309c59b3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'card_detection_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c166667-9619-4c1f-b1e1-488e24f31d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_cards(image_path, model, transform, device):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    return dataset.classes[predicted.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab17b4b0-e960-4f5d-a28b-06f33ab5900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xm/mdklpdgs63zdhm8zvfg_l6g00000gn/T/ipykernel_61495/2380943978.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('card_detection_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Card: two\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('card_detection_model.pth'))\n",
    "image_path = 'test_images/test_2.png'\n",
    "detected_card = detect_cards(image_path, model, transform, device)\n",
    "print(f'Detected Card: {detected_card}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
